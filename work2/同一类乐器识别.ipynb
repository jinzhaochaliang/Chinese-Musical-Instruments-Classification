{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import soundfile\n",
    "import librosa\n",
    "import h5py\n",
    "import pandas as pd\n",
    "from scipy import signal\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.autograd import Variable\n",
    "from torchvision import models, transforms\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "from sklearn.cluster import KMeans\n",
    "\n",
    "import numpy as np\n",
    "from sklearn import datasets\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.svm import SVC\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import accuracy_score\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "class net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(net, self).__init__()\n",
    "        self.net = models.resnet50(pretrained=True)\n",
    " \n",
    "    def forward(self, input):\n",
    "        output = self.net.conv1(input)\n",
    "        output = self.net.bn1(output)\n",
    "        output = self.net.relu(output)\n",
    "        output = self.net.maxpool(output)\n",
    "        output = self.net.layer1(output)\n",
    "        output = self.net.layer2(output)\n",
    "        output = self.net.layer3(output)\n",
    "        output = self.net.layer4(output)\n",
    "        output = self.net.avgpool(output)\n",
    "        return output\n",
    "\n",
    "def get_model():\n",
    "    model = net()\n",
    "    model = model.eval()\n",
    "    model.cuda()\n",
    "    return model\n",
    "\n",
    "to_tensor = transforms.ToTensor()\n",
    "normalize = transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
    "                                 std=[0.229, 0.224, 0.225])\n",
    "\n",
    "def extract_features(model,fea):\n",
    "    model.eval()\n",
    "    \n",
    "    new_img = Image.fromarray(fea.astype(np.float32))\n",
    "    new_img = new_img.resize((224,224))\n",
    "    fea = np.array(new_img.getdata(),dtype=np.float32).reshape(224,224)\n",
    "    \n",
    "    fea = np.resize(fea,(224,224,3))\n",
    "    tensor = normalize(to_tensor(fea))\n",
    "    tensor = tensor.cuda()\n",
    "    res = model(Variable(tensor).unsqueeze(0))\n",
    "    res = res.data.squeeze()\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(name):\n",
    "    print(name)\n",
    "    df = pd.DataFrame(pd.read_excel(name+'.xlsx'))\n",
    "    \n",
    "    audioname = []\n",
    "    num = 0\n",
    "    audioset = {}\n",
    "    n = df.shape[0]\n",
    "    for i in range(n):\n",
    "        if i is not 0:\n",
    "            if df.iloc[i,2] is not df.iloc[i-1,2]:\n",
    "                num += 1\n",
    "        audioname.append(num)\n",
    "        audioset[str(df.iloc[i,2])] = num\n",
    "        \n",
    "    audiofeature = np.load(name+'.npy',allow_pickle=True)\n",
    "    features = []\n",
    "    model = get_model()\n",
    "    for fea in audiofeature:\n",
    "        res = extract_features(model,fea)\n",
    "        features.append(res.tolist())\n",
    "    print(len(features))\n",
    "    \n",
    "    X = np.array(features)\n",
    "    y = np.array(audioname)\n",
    "    x_train,x_test,y_train,y_test = train_test_split(X,y,test_size=0.2,random_state=99)\n",
    "    clf = SVC(C=20,kernel='rbf',gamma='auto',decision_function_shape='ovr')\n",
    "    clf.fit(x_train, y_train)\n",
    "    print(clf.score(x_test,y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "吹奏类\n",
      "2092\n",
      "0.8687350835322196\n"
     ]
    }
   ],
   "source": [
    "train('吹奏类')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "弹拨类\n",
      "1240\n",
      "0.6653225806451613\n",
      "拉弦类\n",
      "1028\n",
      "0.7524271844660194\n",
      "敲击类\n",
      "620\n",
      "0.8064516129032258\n"
     ]
    }
   ],
   "source": [
    "train('弹拨类')\n",
    "train('拉弦类')\n",
    "train('敲击类')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
